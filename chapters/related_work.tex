This chapter consists of two sections, the first one shows an overview some of the
different methods that have been previously used in the literature
for understanding or estimating urban perception, these methods are separated
into 3 types: the classic approaches (all the methods not relying on
massive amounts of data are grouped here), approaches based on machine learning and
approaches consisting of machine learning models combined with other techniques.
The different methods are explained briefly and a short discussion is presented.
Section two summarizes the main aspects of the research
on explainability on deep learning, and describes some techniques that have been applied
in urban perception or other domains that are relevant for this work.


\section{Solutions for estimating urban perception.}

\subsection{Classic approaches.}
Methods for measuring perception of urban spaces have appeared in the literature of several
disciplines for many years,  with some of the most influential studies dating back to 1960
\cite{lynch}. Due to technological limits the literature consisted mainly of several types of
qualitative surveys for a long time. This surveys consisted in having subjects, complete
different tasks such as drawing maps of a certain place \cite{lynch}, evaluating fundamental
aspects of a neighborhood \cite{nasar_perception}, or in more recent approaches evaluating
the impact of transformations generated with edited images \cite{jiang_minimizing}. Most of
these surveys were conducted in person or by phone, and then the results were analyzed manually,
making it very difficult and costly to scale to multiple locations, or larger amounts of samples.
The main benefit of this approach, is that it permits a very refined control of the observation process
since both the subjects being interviewed and the spaces in question are chosen by the researcher.
Added to that, the experiments conducted in person allow for the observer to use senses different
than vision to analyze the subject space, resulting in a richer appreciation.

Other methodology, more common in economics and engineering, consists of using discrete choice models
and stated choice surveys to model the effect of different variables in perception or other urban
related variables  \cite{rose_sc, iglesias_perception, torres_housing}. The amount and complexity of the
variables measured depends on the model design. To have and exact control of the variables that
have an effect on the survey, computer generated images of urban spaces can be used
\cite{iglesias_perception,torres_housing}.

The advantage of this method is that through the estimated parameters of the model, the effect
of each of the studied variables on the perception estimation can be measured, allowing for
quantitative results and an understanding of the impact different elements have on the
perception of the urban landscape. The main disadvantage of this approach comes from the
difficulty of the  survey design, variables need to be chosen carefully and the process its
vulnerable to biases from the model designer.

\subsection{Pure machine learning approaches.}

Thanks to the massive adoption of web and mobile technologies such as google maps, new types of
data are available in considerably large volumes, and new highly scalable ways of  generating data can be
designed and implemented quickly. That fact allows for some very data dependent machine learning
algorithms to be applied to new  problems, including urban perception estimation. Several different
datasets have been proposed for this problem, most of them based on surveys over large amounts of urban images
\cite{hidalgo_inequality, hidalgo_placepulse, quercia_aesthetic, liu_machine, santani}. The most important
of them, all consisting of pairwise comparisons of street view images, are \textit{Place pulse 1.0} (PP 1) \cite{hidalgo_inequality}
with measures of safety, class and uniqueness over images of 4 cities, \textit{Urban Gems} with measures of
beauty, quietness and happiness over images of London and \textit{Place pulse 2.0} (PP 2) \cite{hidalgo_placepulse}, the largest dataset
available, with measures of six different attributes over images of 56 different cities, the models proposed on this work are
trained on this dataset. All of these were collected through public online surveys of large scale, where the users
are asked to choose the image most representative of an attribute of a pair, see figure \ref{fig:survey} for an example.

\begin{figure}[ht]
	\begin{center}
	\includegraphics[width=0.5\textwidth]{./figures/placepulse.png}
	\caption[Place pulse 2.0 survey]{Snapshot of the place pulse 2.0 survey. Extracted from \citeA{hidalgo_placepulse} }
	\label{fig:survey}
	\end{center}
\end{figure}

Earlier attempts at using this data for training models tried to turn the problem into a classification problem
by  ranking the images from the votes with manually engineered methods such as the one suggested on the
place pulse 1.0 paper \cite{hidalgo_inequality} and use the rank to split the data in two halves with a different
label, \citeA{tamara_judgments} use this approach to train SVM models on PP 1 using different types of visual features as input,
including a deep neural network. On the PP 2 paper, the authors present the first end to end deep learning model for
urban perception regression, which uses a typical transfer learning technique \cite{survey_transfer}, a
Imagenet \cite{imagenet} pretrained  network for the base of the model, which is used as input
for by two parallel modules, one for classification and one for regression. They train the architecture
separately on the 6 different attributes of the dataset, the models learn to emulate human voting and
to output a urban perception score (through the regression module) on the image for the correspondent attribute.
Other works \cite{porzi_predicting, santani} take similar approaches but pretrain models or use features based on
the places dataset \cite{zhou_places}, which provides better performance according to their results.


\citeA{zhang_measuring}, train models on PP 2 by combining a DCNN features and a SVM classifier, they use this model to
obtain perception indicators of Beijing, they also use a semantic segmentation model \cite{cordts_cityscapes} on the images and used the results
as input to a linear regression, interpreting the regression weights as an indication of importance of the different segmentation
classes on perception. On a following work \cite{zhang_uncovering} they train one deep network to predict all 6 attributes of PP 2
in one forward pass, they do this using an end-to-end architecture similar to \citeA{hidalgo_placepulse} but adding
one output and loss component for each attribute.

Is important to note that most of the literature so far is more focused on applying the models to new cities
\cite{zhang_measuring, santani, costa_lisbon, rossetti} or generating new datasets with new attributes
\cite{santani, zhang_uncovering}, than it is on improving model  design and performance.
This is consistent with the fact that so far no good measures of performance for this problem have been defined,
due to the fact that the datasets don't provide a measure of perception per se but a proxy through the survey votes.
The objective of the models in the literature is to rank the images by the estimated perception of an attribute, but
they measure  performance on the task of emulating the human votes, which doesn't necessarily correlate with the
models capacity to generalize and rank well, especially in conflicted cases where even human voters
would have difficulties \cite{zhang_measuring}.

\subsection{Mixed approaches.}

With the intention of generating more or different insights, usually more explainability, some
work in the literature consists of combinations of computer vision or machine learning methods
with other techniques. In \citeA{rossetti} the authors use a combination of low and high level features
of the images as input for a discrete choice model that calculates perception. They extract low level features
with traditional computer vision methods like edges or blobs and the high level features with a pretrained
neural network for semantic segmentation. The semantic segmentation features allow for a posthoc analysis of
the results, the authors reach conclusions like "Images with more sidewalks were deemed to be
safer, livelier and wealthier, but less beautiful on average" and they present a table with the significance
of each of the segmentation classes in each of the six PP 2 attributes according to the discrete model parameters.
On a similar line, as was mentioned earlier \citeA{zhang_measuring} in addition to their main method, use
semantic segmentation features (they aggregate them by percentage of pixels on the image)
as an input for multivariate linear regression allowing for similar conclusions to those of \citeA{rossetti}
but using the beta coefficients (see figure \ref{fig:beta}).


\begin{figure}[ht]
	\begin{center}
	\includegraphics[width=1\textwidth]{./figures/zhang.png}
	\caption[Beta Coefficients]{ Linear regression beta coefficients for most significant objects. Extracted from \citeA{zhang_measuring} }
	\label{fig:beta}
	\end{center}
\end{figure}




\section{ Explainability in deep learning.}