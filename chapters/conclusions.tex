Thanks to the massive increase on availability of large amounts of data and the advancements
of deep learning, new ways to approach old problems have become possible in a wide
range of fields. This models usually provide more effective and generalizable solutions,
but take away a large portion of the result interpretability and the capacity to understand
what the models are truly doing. The modelling of urban perception has made use
of these advancements with good success, but the subjective nature of the problem
makes it a task that is specially affected by the lack of explainability of modern
machine learning algorithms. Due to that the recent literature has presented hybrid methods
combining regression or discrete choice models with high level features extracted
with pretrained neural networks such semantic segmentation or object detection.
This techniques provide a better understanding of what is happening inside the model
but sacrifice the higher expressiveness and performance that neural networks
provide when trained end to end.

In this work we presented a novel neural network architecture, aimed at tackling this problem,
through the use of semantic segmentation combined with standard deep learning methods like
fine tuning convolutional features and attention mechanisms. This model is capable of
successfully estimating the perception  with a similar performance than those in the literature,
but at the same time it outputs the attention weights and the segmentation of the image providing
additional data that is human interpretable. We also present an aggregated analysis and visualizations
of the results, that show that attention weights are a good tool for augmenting model explainability.

\section{Contribution to the state of the art.}

\subsection{Enhancing explainability through high level features and attention.}
The main contribution of this research is an end to end trainable neural network
architecture for urban perception quantification that presents very desirable
explainability properties. Unlike previous approaches in urban perception our models
have the capacity to generate explainable insights on an instance level thanks to the
semantic attention weights, making it a considerably more powerful tool both
for research and practical application.

Additionally, the analysis on an aggregated level of segmentation and attention weights
allows to draw similar conclusions to those from previous research, that based their models
on more simple and interpretable techniques such as linear regression or econometric models,
meaning that our architecture achieves an at least as good level of explainability
but with a significantly more expressive and performing deep neural network.

\subsection{Semantic segmentation as part of a neural network.}
The AttentionSegRank neural architecture that we propose, contributes with a novel way of combining
semantic segmentation with traditional deep convolutional features through the attention operations,
allowing the network to learn the capacity of dynamically choosing which parts of an image to attend
based on the semantic classes of the segmentation. This idea is not exclusive to the urban perception task
nor to ranking problems, and may be used for classification or regression in any computer vision task
that allows for a pretrained segmentator to be used or that has available data to train a new one from
scratch.

We think that this approach could prove useful on other vision domains where an improvement
in model explainability is needed without sacrificing too much performance.

\section{Future research directions.}

\subsection{Improving dataset quality.}
Though it's very useful, the Place Pulse 2.0 dataset, it's very poor annotation wise and due to
the way it was designed, changes on the google street view api are  slowly deprecating it. These
problems make it hard for standardizing performance results and therefore
making research that can be replicated easily. Generating a new dataset through a more strict process
and with richer high level annotations, such as segmentation labels could open many doors for new research.

For example, experimenting if training the segmentator on the same dataset where the actual perception quantification
will be learnt, or even training both things at the same time improves either performance
or model explainability poses a very interesting research topic.

\subsection{Additional high level features.}
There is also a possibility to experiment with other types of high level vision futures, such as object
detection, which could serve either as a complement or as a replacement for semantic segmentation.
Previous work has shown that object detectors are useful for quantifying urban perception \cite{rossetti},
and therefore it remains an important open question if a deep learning model integrating an object detector
in its pipeline could improve either performance or explainability.

\subsection{Improved attention mechanisms.}
The attention mechanism used in this work is a simplified version of the now widely
used transformer \cite{vaswani_attention}. Recent research has applied transformers and other similar
attention mechanisms to several computer vision problems with great success. We abstained from using
these techniques in our models because we made an effort to keep the models as simple as possible in order
to reduce the black box nature of these very complex architectures. Improving over AttentionSegRank with
a more modern, better performing attention mechanism and devising a way to keep a similar level of explainability
with it, would be a very important contribution to the computer vision field.