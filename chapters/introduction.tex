\section{Importance of automatic urban perception}

\textit{Urban perception} is a feeling held by people about a location. These feelings can be and
are often related to a particular characteristic, like happiness or beauty, or also
inherently negative ones, like insecurity or fear \cite{tamara_judgments}.

The visual urban perception is  responsible for a large parte of the experience that people
go through while  being at or using an urban space, this not only affects how much the spaces
themselves are used \cite{khisty} but also the use of related means of transport \cite{antonakos}.
Other studies have also found correlations between urban perception, crime statistics \cite{tamara_judgments}
and wealth, and therefore used it as a proxy measure of inequality \cite{tamara_judgments,hidalgo_inequality, rossetti}.

On the other hand, being able to understand a community's need and perception of a city at scale is something
of key importance on developing cities, in order for the limited  resources of local governments to be applied
appropriately \cite{santani}, but traditional methods for the measuring of urban perception, consist of hand made polls
about specific locations making it a extremely costly and hard to escalate process \cite{clifton}.

Considering these facts, automatic estimation of urban perception at great scales becomes a very relevant
research problem, because the generated data would be a powerful tool to guide the improvement of
public spaces and the design of public policy.

\section{Importance of explainability in deep learning.}

Currently, thanks to the great volumes of data generated by web platforms \cite{hidalgo_inequality}
and to modern deep learning techniques \cite{lecun_dl}, the problem of estimating urban perception
has become feasible, and some previous studies have achieved relevant results \cite{hidalgo_placepulse,rossetti}.

However, current deep learning methodologies, have the disadvantage of being "black boxes", in other
words, they lack a direct or systematic way to explain or interpret the obtained results. This problems
comes from the end to end nature of the neural network models and from the millions of learnable parameters
they contain. Many of the problems in which these models are used would greatly benefit of more
human understandable explanations of the results, making this a very important area of
research for the deep learning field \cite{adadi_xai}.  Current research in this matter is primarily
moving in two directions: one is to design novel neural network architectures and training methods so
the models are more interpretable, such as the work by \citeA{yinpeng_semantic}, the other
direction is to  create post-hoc algorithms \cite{adadi_xai} that analyze the results given by the
neural network, these algorithms sometimes use other machine learning models, including neural networls,
such as the work by \citeA{ghorbani_xai}.

For the particular case of urban perception, explainability of the results is highly relevant, since
the added information is valuable for the design of public policy, for example, it could be use to
better discriminate which locations would be better recipients of an intervention, and which elements
to modify so it convenes an effective improvement of perception

\section{Problem Definition}


\section{Thesis outline.}
ESTO HAY QUE ARREGLARLO AL FINAL \\
The remainder of this manuscript is organized as follows, Chapter 3 summarizes relevant previous research. In chapter 4
the problem is formally defined and the proposed model is described. Chapter 5 gives
details on model implementation and training. Finally, in chapter 6 presents the research results
and 7 the final conclusion.
